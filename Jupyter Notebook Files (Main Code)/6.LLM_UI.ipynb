{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJBlWO7jb7Zl",
        "outputId": "a18e7f33-d9d5-493d-ca71-e14018fa1738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/rossmann_dw.db /content/\n",
        "\n",
        "!cp /content/drive/MyDrive/tree_predictions.csv /content/\n",
        "\n",
        "!cp /content/drive/MyDrive/lstm_predictions.csv /content/"
      ],
      "metadata": {
        "id": "R05J2cpb_xQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4MFzOPq-M12"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# اتصال به دیتابیس\n",
        "engine = create_engine('sqlite:///rossmann_dw.db')\n",
        "\n",
        "# خواندن جدول‌ها\n",
        "fact_sales = pd.read_sql('SELECT * FROM fact_sales', engine)\n",
        "dim_store = pd.read_sql('SELECT * FROM dim_store', engine)\n",
        "dim_date = pd.read_sql('SELECT * FROM dim_date', engine)\n",
        "\n",
        "df = fact_sales.merge(dim_store, on='store_id', how='left')\n",
        "df = df.merge(dim_date, on='date_id', how='left')\n",
        "\n",
        "main_df = df.copy()\n",
        "predictions = pd.read_csv('tree_predictions.csv')\n",
        "lstm_predictions = pd.read_csv('lstm_predictions.csv')\n",
        "\n",
        "predictions['preds_lstm'] = lstm_predictions['y_pred']\n",
        "predictions['store_id'] = predictions['store_id'].apply(lambda x: x+1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from typing import Dict, Any, List, Optional, Tuple, Sequence\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import requests\n",
        "\n",
        "# ================= CONFIG =================\n",
        "LLM_PROVIDER = \"groq\"\n",
        "GROQ_API_KEY = userdata.get(\"GROQ_API_KEY\")\n",
        "GROQ_MODEL = 'llama3-70b-8192'\n",
        "\n",
        "predictions_df = predictions\n",
        "\n",
        "REQUIRED_PRED_COLS = {\"store_id\", \"date_id\", \"preds_lgb\", \"preds_xgb\", \"preds_lstm\"}\n",
        "MODEL_COLS = {\"lgb\": \"preds_lgb\", \"xgb\": \"preds_xgb\", \"lstm\": \"preds_lstm\"}\n",
        "\n",
        "# ================= LLM (chat + router) =================\n",
        "def llm_chat(messages: List[Dict[str, str]]) -> str:\n",
        "    if not GROQ_API_KEY:\n",
        "        return \"(LLM offline)\"\n",
        "    try:\n",
        "        url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "        headers = {\"Authorization\": f\"Bearer {GROQ_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
        "        payload = {\"model\": GROQ_MODEL, \"messages\": messages, \"temperature\": 0.2, \"max_tokens\": 512}\n",
        "        r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)\n",
        "        r.raise_for_status()\n",
        "        return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception as e:\n",
        "        return f\"(LLM error) {e}\"\n",
        "\n",
        "def _extract_json(s: str) -> Optional[dict]:\n",
        "    \"\"\"Extract first JSON object from a string (handles extra prose/code fences).\"\"\"\n",
        "    try:\n",
        "        # Fast path\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # Fallback: find first {...}\n",
        "    try:\n",
        "        m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n",
        "        if m:\n",
        "            return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "def _normalize_model(m: Optional[str]) -> Optional[str]:\n",
        "    if not m:\n",
        "        return None\n",
        "    t = m.strip().lower()\n",
        "    if any(x in t for x in [\"lgb\", \"lightgbm\", \"lgbm\"]): return \"lgb\"\n",
        "    if any(x in t for x in [\"xgb\", \"xgboost\"]): return \"xgb\"\n",
        "    if \"lstm\" in t: return \"lstm\"\n",
        "    return None\n",
        "\n",
        "def llm_route(user_text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask the LLM to infer which action to run and which parameters to use.\n",
        "    Returns a dict like:\n",
        "      {\"type\": \"...\", \"model\": \"...\", \"store\": int, \"k\": int, \"models\": [...], \"group_col\": \"...\"}\n",
        "    \"\"\"\n",
        "    system = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You route user requests to analytics actions for Rossmann sales predictions. \"\n",
        "            \"Always respond with STRICT JSON, no commentary. \"\n",
        "            \"Schema keys: type (one of: next_month, next_week, compare_next_month, topk_next_week, group_next_month, freeform); \"\n",
        "            \"model (lgb|xgb|lstm); models (array of models for comparison); store (int); k (int); group_col (string, like store_type/state/promo). \"\n",
        "            \"If a needed field is missing, infer it. If genuinely unknown, omit it. \"\n",
        "            \"For Top-K, default model=lgb if user didn't specify. \"\n",
        "            \"Examples:\\n\"\n",
        "            \"{'type':'next_month','model':'lgb','store':1}\\n\"\n",
        "            \"{'type':'next_week','model':'xgb','store':20}\\n\"\n",
        "            \"{'type':'compare_next_month','models':['lgb','xgb','lstm'],'store':10}\\n\"\n",
        "            \"{'type':'topk_next_week','k':5,'model':'xgb'}\\n\"\n",
        "            \"{'type':'group_next_month','group_col':'store_type'}\"\n",
        "        )\n",
        "    }\n",
        "    user = {\"role\": \"user\", \"content\": f\"User request: {user_text}\\nReturn ONLY JSON.\"}\n",
        "    raw = llm_chat([system, user])\n",
        "\n",
        "    data = _extract_json(raw) or {}\n",
        "    # Normalize/guard\n",
        "    t = data.get(\"type\") or \"freeform\"\n",
        "    model = _normalize_model(data.get(\"model\"))\n",
        "    if not model and t == \"topk_next_week\":\n",
        "        model = \"lgb\"  # default for Top-K if omitted\n",
        "    # Normalize list of models for compare\n",
        "    if data.get(\"models\"):\n",
        "        data[\"models\"] = [m for m in [\"lgb\", \"xgb\", \"lstm\"] if _normalize_model(m) in {\"lgb\", \"xgb\", \"lstm\"} and m in [ _normalize_model(x) or \"\" for x in data[\"models\"] ]]\n",
        "        if not data[\"models\"]:\n",
        "            data[\"models\"] = [\"lgb\", \"xgb\", \"lstm\"]\n",
        "    # Clean group col: spaces -> underscores, lower\n",
        "    if data.get(\"group_col\"):\n",
        "        data[\"group_col\"] = re.sub(r\"\\s+\", \"_\", str(data[\"group_col\"]).strip().lower())\n",
        "\n",
        "    # Coerce ints\n",
        "    for key in [\"store\", \"k\"]:\n",
        "        if key in data and data[key] is not None:\n",
        "            try:\n",
        "                data[key] = int(data[key])\n",
        "            except Exception:\n",
        "                data[key] = None\n",
        "\n",
        "    return {\n",
        "        \"type\": t,\n",
        "        \"model\": model,\n",
        "        \"models\": data.get(\"models\"),\n",
        "        \"store\": data.get(\"store\"),\n",
        "        \"k\": data.get(\"k\"),\n",
        "        \"group_col\": data.get(\"group_col\"),\n",
        "    }\n",
        "\n",
        "# ================= PREPARE DATA =================\n",
        "def _ensure_cols(df: pd.DataFrame, needed: Sequence[str], name: str):\n",
        "    missing = set(needed) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{name} missing required columns: {sorted(missing)}\")\n",
        "\n",
        "_ensure_cols(predictions_df, REQUIRED_PRED_COLS, \"predictions_df\")\n",
        "predictions_df = predictions_df.copy()\n",
        "predictions_df[\"date_id\"] = pd.to_datetime(predictions_df[\"date_id\"])\n",
        "\n",
        "# normalize main_df store id column to 'store_id' if it's 'Store'\n",
        "main_df = main_df.copy()\n",
        "if \"store_id\" not in main_df.columns and \"Store\" in main_df.columns:\n",
        "    main_df = main_df.rename(columns={\"Store\": \"store_id\"})\n",
        "if \"store_id\" not in main_df.columns:\n",
        "    pass\n",
        "\n",
        "# ================= PLOTTING HELPERS =================\n",
        "def _save_fig_to_image(fig) -> Image.Image:\n",
        "    buf = io.BytesIO()\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(buf, format=\"png\", dpi=160)\n",
        "    plt.close(fig)\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def make_line_image(dates: pd.Series, values: pd.Series, title: str, ylabel: str = \"Predicted Sales\") -> Image.Image:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
        "    ax.plot(dates, values, marker=\"o\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    fig.autofmt_xdate()\n",
        "    return _save_fig_to_image(fig)\n",
        "\n",
        "def make_multi_line_image(dates: pd.Series, series_dict: Dict[str, pd.Series], title: str, ylabel: str = \"Predicted Sales\") -> Image.Image:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
        "    for label, vals in series_dict.items():\n",
        "        ax.plot(dates, vals, marker=\"o\", label=label)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    ax.legend()\n",
        "    fig.autofmt_xdate()\n",
        "    return _save_fig_to_image(fig)\n",
        "\n",
        "def make_bar_image(categories: Sequence[str], values: Sequence[float], title: str, xlabel: str = \"\", ylabel: str = \"Predicted Sales\") -> Image.Image:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4.5))\n",
        "    ax.bar(range(len(categories)), values)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(range(len(categories)))\n",
        "    ax.set_xticklabels(categories, rotation=30, ha=\"right\")\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "    return _save_fig_to_image(fig)\n",
        "\n",
        "# ================= SHARED DATE HELPERS =================\n",
        "def get_next_month_period(df: pd.DataFrame) -> pd.Period:\n",
        "    \"\"\"Pick the earliest month in the future; fallback to the latest month in df.\"\"\"\n",
        "    df = df.copy()\n",
        "    df[\"ym\"] = df[\"date_id\"].dt.to_period(\"M\")\n",
        "    today = pd.Timestamp.today().normalize()\n",
        "    future = df[df[\"date_id\"] >= today]\n",
        "    return (future[\"ym\"].min() if not future.empty else df[\"ym\"].max())\n",
        "\n",
        "def get_next_7_dates(df: pd.DataFrame) -> List[pd.Timestamp]:\n",
        "    \"\"\"Earliest 7 unique dates in the future across the whole predictions_df; fallback to first 7 overall.\"\"\"\n",
        "    all_dates = df[\"date_id\"].sort_values().unique()\n",
        "    today = pd.Timestamp.today().normalize()\n",
        "    future = [d for d in all_dates if d >= today]\n",
        "    window = future[:7] if len(future) >= 7 else list(all_dates[:7])\n",
        "    return list(pd.to_datetime(window))\n",
        "\n",
        "# ================= HANDLERS =================\n",
        "def handle_next_month(model: str, store: int) -> Tuple[str, Optional[Image.Image]]:\n",
        "    df = predictions_df.query(\"store_id == @store\").copy()\n",
        "    if df.empty:\n",
        "        return f\"No predictions for store {store}.\", None\n",
        "    target_month = get_next_month_period(df)\n",
        "    frame = (df.assign(month=df[\"date_id\"].dt.to_period(\"M\"))\n",
        "               .loc[lambda d: d[\"month\"] == target_month]\n",
        "               .sort_values(\"date_id\"))\n",
        "    img = make_line_image(\n",
        "        dates=frame[\"date_id\"], values=frame[MODEL_COLS[model]],\n",
        "        title=f\"Store {store} — Next Month ({target_month}) — {model.upper()}\"\n",
        "    )\n",
        "    total = float(frame[MODEL_COLS[model]].sum())\n",
        "    return f\"{model.upper()} forecast for store {store}, month {target_month}. Total: {total:,.2f}\", img\n",
        "\n",
        "def handle_next_week(model: str, store: int) -> Tuple[str, Optional[Image.Image]]:\n",
        "    df = predictions_df.query(\"store_id == @store\").sort_values(\"date_id\")\n",
        "    if df.empty:\n",
        "        return f\"No predictions for store {store}.\", None\n",
        "    week_dates = get_next_7_dates(predictions_df)\n",
        "    week = df[df[\"date_id\"].isin(week_dates)]\n",
        "    if len(week) == 0:\n",
        "        week = df.head(7)\n",
        "    img = make_line_image(\n",
        "        dates=week[\"date_id\"], values=week[MODEL_COLS[model]],\n",
        "        title=f\"Store {store} — Next 7 Days — {model.upper()}\"\n",
        "    )\n",
        "    total = float(week[MODEL_COLS[model]].sum())\n",
        "    start = week[\"date_id\"].min().date()\n",
        "    end = week[\"date_id\"].max().date()\n",
        "    return f\"{model.upper()} forecast for store {store} ({start} → {end}). Total: {total:,.2f}\", img\n",
        "\n",
        "def handle_compare_next_month(models: List[str], store: int) -> Tuple[str, Optional[Image.Image]]:\n",
        "    df = predictions_df.query(\"store_id == @store\").copy()\n",
        "    if df.empty:\n",
        "        return f\"No predictions for store {store}.\", None\n",
        "    target_month = get_next_month_period(df)\n",
        "    frame = (df.assign(month=df[\"date_id\"].dt.to_period(\"M\"))\n",
        "               .loc[lambda d: d[\"month\"] == target_month]\n",
        "               .sort_values(\"date_id\"))\n",
        "\n",
        "    if frame.empty:\n",
        "        return f\"No next-month rows available for store {store}.\", None\n",
        "\n",
        "    series_dict = {}\n",
        "    totals = []\n",
        "    for m in models:\n",
        "        col = MODEL_COLS[m]\n",
        "        series_dict[m.upper()] = frame[col]\n",
        "        totals.append((m.upper(), float(frame[col].sum())))\n",
        "\n",
        "    img = make_multi_line_image(\n",
        "        dates=frame[\"date_id\"], series_dict=series_dict,\n",
        "        title=f\"Store {store} — Next Month ({target_month}) — Model Comparison\"\n",
        "    )\n",
        "    totals_str = \" | \".join([f\"{name}: {val:,.2f}\" for name, val in totals])\n",
        "    return f\"Monthly totals — {totals_str}\", img\n",
        "\n",
        "def handle_topk_next_week(k: int, model: str) -> Tuple[str, Optional[Image.Image]]:\n",
        "    # Compute the same 7-day horizon for all stores\n",
        "    week_dates = set(get_next_7_dates(predictions_df))\n",
        "    df_week = predictions_df[predictions_df[\"date_id\"].isin(week_dates)]\n",
        "    if df_week.empty:\n",
        "        # fallback: first 7 days overall\n",
        "        first7 = predictions_df[\"date_id\"].sort_values().unique()[:7]\n",
        "        df_week = predictions_df[predictions_df[\"date_id\"].isin(first7)]\n",
        "\n",
        "    agg = (df_week.groupby(\"store_id\", as_index=False)[MODEL_COLS[model]]\n",
        "           .sum()\n",
        "           .rename(columns={MODEL_COLS[model]: \"pred_total\"}))\n",
        "    if agg.empty:\n",
        "        return \"No data available to rank stores.\", None\n",
        "\n",
        "    topk = agg.sort_values(\"pred_total\", ascending=False).head(k)\n",
        "    # Bar chart\n",
        "    cats = [str(s) for s in topk[\"store_id\"]]\n",
        "    vals = [float(v) for v in topk[\"pred_total\"]]\n",
        "    img = make_bar_image(cats, vals, title=f\"Top {k} Stores — Next 7 Days — {model.upper()}\", xlabel=\"Store ID\")\n",
        "\n",
        "    # Text table\n",
        "    lines = [f\"{i+1}. Store {sid}: {v:,.2f}\" for i, (sid, v) in enumerate(zip(topk[\"store_id\"], topk[\"pred_total\"]))]\n",
        "    return \"Leaderboard (sum of next 7 days):\\n\" + \"\\n\".join(lines), img\n",
        "\n",
        "def handle_group_next_month(group_col: str) -> Tuple[str, Optional[Image.Image]]:\n",
        "    if \"store_id\" not in main_df.columns:\n",
        "        return (\"Aggregation needs main_df with a 'store_id' column \"\n",
        "                f\"(found columns: {list(main_df.columns)[:8]}...)\"), None\n",
        "    if group_col not in main_df.columns:\n",
        "        candidates = {c.lower(): c for c in main_df.columns}\n",
        "        if group_col.lower() in candidates:\n",
        "            group_col = candidates[group_col.lower()]\n",
        "        else:\n",
        "            return f\"main_df does not have a '{group_col}' column.\", None\n",
        "\n",
        "    target_month = get_next_month_period(predictions_df)\n",
        "    df_month = (predictions_df.assign(month=predictions_df[\"date_id\"].dt.to_period(\"M\"))\n",
        "                              .loc[lambda d: d[\"month\"] == target_month]\n",
        "                              .copy())\n",
        "    if df_month.empty:\n",
        "        return \"No rows for the next month horizon.\", None\n",
        "\n",
        "    # prepare store attributes (distinct per store)\n",
        "    store_attrs = main_df[[\"store_id\", group_col]].drop_duplicates(subset=[\"store_id\"]).copy()\n",
        "    # join attributes to predictions\n",
        "    joined = df_month.merge(store_attrs, on=\"store_id\", how=\"left\")\n",
        "\n",
        "    # if any stores missing attribute, label as \"Unknown\"\n",
        "    joined[group_col] = joined[group_col].fillna(\"Unknown\")\n",
        "\n",
        "    model = \"lgb\"\n",
        "    agg = joined.groupby(group_col, as_index=False)[MODEL_COLS[model]].sum()\n",
        "    if agg.empty:\n",
        "        return \"No aggregated data available.\", None\n",
        "\n",
        "    cats = [str(x) for x in agg[group_col]]\n",
        "    vals = [float(x) for x in agg[MODEL_COLS[model]]]\n",
        "    img = make_bar_image(cats, vals, title=f\"Next Month by {group_col} — {model.upper()}\")\n",
        "    # Top line text summary\n",
        "    pairs = sorted(zip(cats, vals), key=lambda t: t[1], reverse=True)\n",
        "    head = \" | \".join([f\"{c}: {v:,.0f}\" for c, v in pairs[:5]])\n",
        "    return f\"Total predicted sales ({model.upper()}) for next month ({target_month}) by {group_col}.\\nTop groups: {head}\", img\n",
        "\n",
        "# ================= ROUTER =================\n",
        "def agent_router(user_text: str, chat_history: List[List[Any]]) -> Tuple[List[List[Any]], Optional[Image.Image]]:\n",
        "    intent = llm_route(user_text)\n",
        "\n",
        "    if intent[\"type\"] == \"next_month\" and intent.get(\"model\") and intent.get(\"store\") is not None:\n",
        "        msg, img = handle_next_month(intent[\"model\"], int(intent[\"store\"]))\n",
        "        return chat_history + [[user_text, msg]], img\n",
        "\n",
        "    if intent[\"type\"] == \"next_week\" and intent.get(\"model\") and intent.get(\"store\") is not None:\n",
        "        msg, img = handle_next_week(intent[\"model\"], int(intent[\"store\"]))\n",
        "        return chat_history + [[user_text, msg]], img\n",
        "\n",
        "    if intent[\"type\"] == \"compare_next_month\" and intent.get(\"models\") and intent.get(\"store\") is not None:\n",
        "        msg, img = handle_compare_next_month(intent[\"models\"], int(intent[\"store\"]))\n",
        "        return chat_history + [[user_text, msg]], img\n",
        "\n",
        "    if intent[\"type\"] == \"topk_next_week\":\n",
        "        k = intent.get(\"k\") or 5\n",
        "        model = intent.get(\"model\") or \"lgb\"\n",
        "        msg, img = handle_topk_next_week(int(k), model)\n",
        "        return chat_history + [[user_text, msg]], img\n",
        "\n",
        "    if intent[\"type\"] == \"group_next_month\" and intent.get(\"group_col\"):\n",
        "        msg, img = handle_group_next_month(intent[\"group_col\"])\n",
        "        return chat_history + [[user_text, msg]], img\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a helpful retail analytics agent. \"\n",
        "        \"When the user asks for predictions/analytics, prefer deterministic tools. \"\n",
        "        \"For general questions, be concise and accurate.\"\n",
        "    )\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    for u, a in (chat_history or [])[-5:]:\n",
        "        if u: messages.append({\"role\": \"user\", \"content\": u})\n",
        "        if a: messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
        "    reply = llm_chat(messages)\n",
        "    return chat_history + [[user_text, reply]], None\n",
        "\n",
        "# ================= UI =================\n",
        "WELCOME_MSG = (\n",
        "    \"👋 Hi! I’m your Rossmann Sales Agent.\\n\\n\"\n",
        "    \"**Things I can do:**\\n\"\n",
        "    \"• `predict next (month/week) sales with (lgb/xgb/lstm) model any for store`\\n\"\n",
        "    \"• `compare next month predictions by lgb, xgb, lstm for any store`\\n\"\n",
        "    \"• `show top k stores with highest predicted sales next week with those models`\\n\"\n",
        "    \"• `predict sales by store type next month`\\n\\n\"\n",
        "    \"Ask for other views and I’ll try to help!\"\n",
        ")\n",
        "\n",
        "with gr.Blocks(title=\"Rossmann Sales Agent\", fill_height=True, theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🧠 Rossmann Sales Agent\")\n",
        "    chatbot = gr.Chatbot(value=[[None, WELCOME_MSG]], height=460, label=\"Conversation\")\n",
        "    user_in = gr.Textbox(placeholder=\"Type a request…\", autofocus=True)\n",
        "    send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
        "    plot_img = gr.Image(label=\"Plot\", height=380)\n",
        "\n",
        "    def on_send(user_text, history):\n",
        "        history = history or [[None, WELCOME_MSG]]\n",
        "        new_history, img = agent_router(user_text, history)\n",
        "        return new_history, \"\", img\n",
        "\n",
        "    send_btn.click(on_send, [user_in, chatbot], [chatbot, user_in, plot_img])\n",
        "    user_in.submit(on_send, [user_in, chatbot], [chatbot, user_in, plot_img])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh1J93OwHnvc",
        "outputId": "4dffd598-59f9-4512-d5de-c5ea8e72fc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-441424780.py:372: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(value=[[None, WELCOME_MSG]], height=460, label=\"Conversation\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://38c13ba03961eabb9a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://38c13ba03961eabb9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6onfbjdPYH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}